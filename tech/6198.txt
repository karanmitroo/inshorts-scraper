Google's auto-captioning algorithm claims to describe photos at up to 93.9% accuracy. Named 'Show and Tell', the open-source algorithm can be 'trained' by feeding human-captioned images. Developers expect it to describe 'unseen' images once it has processed a large enough sample of captioned images. The project's initial version was launched in 2014 with an accuracy of up to 89.6%.