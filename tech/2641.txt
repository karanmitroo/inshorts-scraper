Microsoft's chatbot 'Zo', which is programmed to not talk about politics and religion, has faced flak online after it called the Quran "very violent" in a chat. It also claimed that Osama Bin Laden was "captured" after "years of intelligence gathering under more than one administration." Microsoft has said that the errors in Zo's behaviour have now been corrected.